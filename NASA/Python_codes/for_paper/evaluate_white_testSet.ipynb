{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e630d4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy, scipy.signal\n",
    "\n",
    "from datetime import date\n",
    "import time\n",
    "\n",
    "from random import seed\n",
    "from random import random\n",
    "\n",
    "import os, os.path\n",
    "import shutil\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from pylab import imshow\n",
    "\n",
    "import h5py\n",
    "import sys\n",
    "sys.path.append('/Users/hn/Documents/00_GitHub/Ag/NASA/Python_codes/')\n",
    "import NASA_core as nc\n",
    "# import NASA_plot_core.py as rcp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4abc76ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"/Users/hn/Documents/01_research_data/NASA/06_SOS_tables/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e524bd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6340, 8)\n",
      "(3539, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>CropTyp</th>\n",
       "      <th>Irrigtn</th>\n",
       "      <th>DataSrc</th>\n",
       "      <th>Acres</th>\n",
       "      <th>ExctAcr</th>\n",
       "      <th>LstSrvD</th>\n",
       "      <th>county</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100010_WSDA_SF_2017</td>\n",
       "      <td>alfalfa hay</td>\n",
       "      <td>center pivot</td>\n",
       "      <td>wsda</td>\n",
       "      <td>34</td>\n",
       "      <td>34.310305</td>\n",
       "      <td>2017/09/12</td>\n",
       "      <td>Grant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100204_WSDA_SF_2017</td>\n",
       "      <td>alfalfa hay</td>\n",
       "      <td>center pivot</td>\n",
       "      <td>wsda</td>\n",
       "      <td>62</td>\n",
       "      <td>61.826535</td>\n",
       "      <td>2017/08/09</td>\n",
       "      <td>Grant</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    ID      CropTyp       Irrigtn DataSrc  Acres    ExctAcr  \\\n",
       "0  100010_WSDA_SF_2017  alfalfa hay  center pivot    wsda     34  34.310305   \n",
       "1  100204_WSDA_SF_2017  alfalfa hay  center pivot    wsda     62  61.826535   \n",
       "\n",
       "      LstSrvD county  \n",
       "0  2017/09/12  Grant  \n",
       "1  2017/08/09  Grant  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_dir = \"/Users/hn/Documents/01_research_data/NASA/parameters/\"\n",
    "meta = pd.read_csv(meta_dir+\"evaluation_set.csv\")\n",
    "meta_moreThan10Acr=meta[meta.ExctAcr>10]\n",
    "print (meta.shape)\n",
    "print (meta_moreThan10Acr.shape)\n",
    "meta.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f9aa3ac0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Adams', 'Benton', 'Franklin', 'Grant', 'Walla Walla', 'Yakima']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(meta.county.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec4d295e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "244     150030_WSDA_SF_2015\n",
       "247     151525_WSDA_SF_2015\n",
       "248     154028_WSDA_SF_2015\n",
       "249     157039_WSDA_SF_2015\n",
       "250     157040_WSDA_SF_2015\n",
       "               ...         \n",
       "6219    144551_WSDA_SF_2015\n",
       "6220    150442_WSDA_SF_2015\n",
       "6221    162851_WSDA_SF_2015\n",
       "6222    173974_WSDA_SF_2015\n",
       "6223    180631_WSDA_SF_2015\n",
       "Name: ID, Length: 649, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "walla = meta[meta.county==\"Walla Walla\"]\n",
    "walla.ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b7a5d13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b5235ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Votes:  [2 1]\n",
      "1849\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Vote</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>99837_WSDA_SF_2017</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>114615_WSDA_SF_2017</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    ID  Vote\n",
       "0   99837_WSDA_SF_2017     2\n",
       "1  114615_WSDA_SF_2017     1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set_dir = \"/Users/hn/Documents/01_research_data/NASA/ML_data/\"\n",
    "ground_truth_labels = pd.read_csv(training_set_dir+\"train_labels.csv\")\n",
    "print (\"Unique Votes: \", ground_truth_labels.Vote.unique())\n",
    "print (len(ground_truth_labels.ID.unique()))\n",
    "ground_truth_labels.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "17c7f4d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth_labels_extended = pd.merge(ground_truth_labels, meta, on=['ID'], how='left')\n",
    "ground_truth_labels = ground_truth_labels_extended[ground_truth_labels_extended.ExctAcr>=10].copy()\n",
    "ground_truth_labels.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4c28003e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1342, 9)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ground_truth_labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be6b8dd5",
   "metadata": {},
   "source": [
    "# Test set (the 20%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f058e56d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(269, 9)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set_dir = \"/Users/hn/Documents/01_research_data/NASA/ML_data/\"\n",
    "testset = pd.read_csv(test_set_dir+\"test20_split_expertLabels_2Bconsistent.csv\")\n",
    "ground_truth_labels_test = ground_truth_labels[ground_truth_labels.ID.isin(list(testset.ID))]\n",
    "ground_truth_labels_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f320b1bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_files = os.listdir(data_dir)\n",
    "\n",
    "NamePattern=\"irr_NoNASS_SurvCorrect\"\n",
    "files_with_3_filters = [x for x in all_files if NamePattern in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bd46c0a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================================================================\n",
      "this must be 269: 269\n",
      "VI_indeks: NDVI, NDVI_threshold: 3\n",
      "            None  Predict_Single  Predict_Double\n",
      "0  Actual_Single             175              44\n",
      "1  Actual_Double              19              31\n",
      "\n",
      "count difference is 25\n",
      "acr difference is 1026.7778183940616\n",
      "true_double_predicted_single.ExctAcr 1754.0358052667268\n",
      "true_single_predicted_double.ExctAcr 2780.8136236607884\n",
      "\n",
      "==================================================================================================\n",
      "this must be 269: 269\n",
      "VI_indeks: NDVI, NDVI_threshold: 4\n",
      "            None  Predict_Single  Predict_Double\n",
      "0  Actual_Single             174              45\n",
      "1  Actual_Double              11              39\n",
      "\n",
      "count difference is 34\n",
      "acr difference is 1897.496052101365\n",
      "true_double_predicted_single.ExctAcr 1127.890721287638\n",
      "true_single_predicted_double.ExctAcr 3025.386773389003\n",
      "\n",
      "==================================================================================================\n",
      "this must be 269: 269\n",
      "VI_indeks: NDVI, NDVI_threshold: 5\n",
      "            None  Predict_Single  Predict_Double\n",
      "0  Actual_Single             189              30\n",
      "1  Actual_Double              10              40\n",
      "\n",
      "count difference is 20\n",
      "acr difference is 1371.2663614438616\n",
      "true_double_predicted_single.ExctAcr 862.6928968574998\n",
      "true_single_predicted_double.ExctAcr 2233.9592583013614\n",
      "\n",
      "==================================================================================================\n",
      "this must be 269: 269\n",
      "VI_indeks: EVI, NDVI_threshold: 3\n",
      "            None  Predict_Single  Predict_Double\n",
      "0  Actual_Single             173              46\n",
      "1  Actual_Double              10              40\n",
      "\n",
      "count difference is 36\n",
      "acr difference is 1499.84071174363\n",
      "true_double_predicted_single.ExctAcr 1150.916559021649\n",
      "true_single_predicted_double.ExctAcr 2650.757270765279\n",
      "\n",
      "==================================================================================================\n",
      "this must be 269: 269\n",
      "VI_indeks: EVI, NDVI_threshold: 4\n",
      "            None  Predict_Single  Predict_Double\n",
      "0  Actual_Single             186              33\n",
      "1  Actual_Double               6              44\n",
      "\n",
      "count difference is 27\n",
      "acr difference is 1388.999285367337\n",
      "true_double_predicted_single.ExctAcr 533.263368547007\n",
      "true_single_predicted_double.ExctAcr 1922.2626539143441\n",
      "\n",
      "==================================================================================================\n",
      "this must be 269: 269\n",
      "VI_indeks: EVI, NDVI_threshold: 5\n",
      "            None  Predict_Single  Predict_Double\n",
      "0  Actual_Single             197              22\n",
      "1  Actual_Double               9              41\n",
      "\n",
      "count difference is 13\n",
      "acr difference is 419.4921022949204\n",
      "true_double_predicted_single.ExctAcr 682.3910878430884\n",
      "true_single_predicted_double.ExctAcr 1101.8831901380088\n",
      "\n"
     ]
    }
   ],
   "source": [
    "VI_indeksss = [\"NDVI\", \"EVI\"]\n",
    "NDVI_thresholds = [3, 4, 5]\n",
    "\n",
    "VI_indeks=\"EVI\"\n",
    "NDVI_threshold=3\n",
    "\n",
    "for VI_indeks in VI_indeksss:\n",
    "    for NDVI_threshold  in NDVI_thresholds:\n",
    "        all_data = pd.DataFrame()\n",
    "\n",
    "        for fileName in files_with_3_filters:\n",
    "            if VI_indeks+str(NDVI_threshold) in fileName:\n",
    "                a=pd.read_csv(data_dir + fileName)\n",
    "                a['human_system_start_time'] = pd.to_datetime(a['human_system_start_time'])\n",
    "                curr_year = int(fileName.split(\"_\")[2][-4:])\n",
    "                a = a[a['human_system_start_time'].dt.year == curr_year].copy()\n",
    "                a = a[[\"ID\", \"season_count\"]]\n",
    "\n",
    "                all_data=pd.concat([all_data, a])\n",
    "\n",
    "        all_data = all_data[all_data.ID.isin(list(ground_truth_labels_test.ID.unique()))].copy()\n",
    "        all_data.drop_duplicates(inplace=True)\n",
    "        all_data.reset_index(drop=True, inplace=True)\n",
    "        print (\"==================================================================================================\")\n",
    "        single_season=all_data[all_data.season_count<2]\n",
    "        two_seasons=all_data[all_data.season_count>=2]\n",
    "        print (\"this must be 269:\", str(len(single_season)+len(two_seasons)))\n",
    "        \n",
    "        evalHelp = pd.merge(ground_truth_labels_test, all_data, on=['ID'], how='left')\n",
    "        true_single_predicted_single = evalHelp[evalHelp.Vote==1].copy()\n",
    "        true_single_predicted_single = true_single_predicted_single[true_single_predicted_single.season_count<2]\n",
    "\n",
    "\n",
    "        true_double_predicted_double = evalHelp[evalHelp.Vote>=2].copy()\n",
    "        true_double_predicted_double = true_double_predicted_double[true_double_predicted_double.season_count>=2]\n",
    "\n",
    "        true_double_predicted_single=evalHelp[evalHelp.Vote==2].copy()\n",
    "        true_double_predicted_single = true_double_predicted_single[true_double_predicted_single.season_count<2]\n",
    "\n",
    "        true_single_predicted_double=evalHelp[evalHelp.Vote==1].copy()\n",
    "        true_single_predicted_double = true_single_predicted_double[true_single_predicted_double.season_count>=2]\n",
    "\n",
    "\n",
    "        balanced_confus_tbl_test = pd.DataFrame(columns=['None', 'Predict_Single', 'Predict_Double'], \n",
    "                                                index=range(2))\n",
    "        balanced_confus_tbl_test.loc[0, 'None'] = 'Actual_Single'\n",
    "        balanced_confus_tbl_test.loc[1, 'None'] = 'Actual_Double'\n",
    "        balanced_confus_tbl_test['Predict_Single']=0\n",
    "        balanced_confus_tbl_test['Predict_Double']=0\n",
    "\n",
    "        balanced_confus_tbl_test.loc[0, \"Predict_Single\"]=len(true_single_predicted_single)\n",
    "        balanced_confus_tbl_test.loc[0, \"Predict_Double\"]=len(true_single_predicted_double)\n",
    "        balanced_confus_tbl_test.loc[1, \"Predict_Single\"]=len(true_double_predicted_single)\n",
    "        balanced_confus_tbl_test.loc[1, \"Predict_Double\"]=len(true_double_predicted_double)\n",
    "        \n",
    "        print (\"VI_indeks: \" + VI_indeks + \", NDVI_threshold: \" + str(NDVI_threshold))\n",
    "        print (balanced_confus_tbl_test)\n",
    "        print (\"\")\n",
    "        _dc = np.abs(balanced_confus_tbl_test.loc[0, \"Predict_Double\"]-balanced_confus_tbl_test.loc[1, \"Predict_Single\"])\n",
    "        print (\"count difference is \" + str(_dc))\n",
    "        acr_diff=np.abs(true_double_predicted_single.ExctAcr.sum()-true_single_predicted_double.ExctAcr.sum())\n",
    "        print (\"acr difference is \"+str(acr_diff))\n",
    "        print (\"true_double_predicted_single.ExctAcr\", true_double_predicted_single.ExctAcr.sum())\n",
    "        print (\"true_single_predicted_double.ExctAcr\", true_single_predicted_double.ExctAcr.sum())\n",
    "        print ()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a333322",
   "metadata": {},
   "source": [
    "# Drop Walla Walla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "561c8682",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6340, 8)\n",
      "(3539, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>CropTyp</th>\n",
       "      <th>Irrigtn</th>\n",
       "      <th>DataSrc</th>\n",
       "      <th>Acres</th>\n",
       "      <th>ExctAcr</th>\n",
       "      <th>LstSrvD</th>\n",
       "      <th>county</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100010_WSDA_SF_2017</td>\n",
       "      <td>alfalfa hay</td>\n",
       "      <td>center pivot</td>\n",
       "      <td>wsda</td>\n",
       "      <td>34</td>\n",
       "      <td>34.310305</td>\n",
       "      <td>2017/09/12</td>\n",
       "      <td>Grant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100204_WSDA_SF_2017</td>\n",
       "      <td>alfalfa hay</td>\n",
       "      <td>center pivot</td>\n",
       "      <td>wsda</td>\n",
       "      <td>62</td>\n",
       "      <td>61.826535</td>\n",
       "      <td>2017/08/09</td>\n",
       "      <td>Grant</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    ID      CropTyp       Irrigtn DataSrc  Acres    ExctAcr  \\\n",
       "0  100010_WSDA_SF_2017  alfalfa hay  center pivot    wsda     34  34.310305   \n",
       "1  100204_WSDA_SF_2017  alfalfa hay  center pivot    wsda     62  61.826535   \n",
       "\n",
       "      LstSrvD county  \n",
       "0  2017/09/12  Grant  \n",
       "1  2017/08/09  Grant  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_dir = \"/Users/hn/Documents/01_research_data/NASA/parameters/\"\n",
    "meta = pd.read_csv(meta_dir+\"evaluation_set.csv\")\n",
    "meta_moreThan10Acr=meta[meta.ExctAcr>10]\n",
    "print (meta.shape)\n",
    "print (meta_moreThan10Acr.shape)\n",
    "meta.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f6f3281f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Votes:  [2 1]\n",
      "1849\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Vote</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>99837_WSDA_SF_2017</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>114615_WSDA_SF_2017</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    ID  Vote\n",
       "0   99837_WSDA_SF_2017     2\n",
       "1  114615_WSDA_SF_2017     1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set_dir = \"/Users/hn/Documents/01_research_data/NASA/ML_data/\"\n",
    "ground_truth_labels = pd.read_csv(training_set_dir+\"train_labels.csv\")\n",
    "print (\"Unique Votes: \", ground_truth_labels.Vote.unique())\n",
    "print (len(ground_truth_labels.ID.unique()))\n",
    "ground_truth_labels.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "91c04cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth_labels_extended = pd.merge(ground_truth_labels, meta, on=['ID'], how='left')\n",
    "ground_truth_labels = ground_truth_labels_extended[ground_truth_labels_extended.ExctAcr>=10].copy()\n",
    "ground_truth_labels.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ff4f787c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth_labels=ground_truth_labels[ground_truth_labels.county!=\"Walla Walla\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12072500",
   "metadata": {},
   "source": [
    "# Test Set (20%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "48a8bc45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(248, 9)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set_dir = \"/Users/hn/Documents/01_research_data/NASA/ML_data/\"\n",
    "testset = pd.read_csv(test_set_dir+\"test20_split_expertLabels_2Bconsistent.csv\")\n",
    "\n",
    "ground_truth_labels_test = ground_truth_labels[ground_truth_labels.ID.isin(list(testset.ID))]\n",
    "ground_truth_labels_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "33ff91ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_files = os.listdir(data_dir)\n",
    "\n",
    "NamePattern=\"irr_NoNASS_SurvCorrect\"\n",
    "files_with_3_filters = [x for x in all_files if NamePattern in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5308d15f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "713658c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================================================================\n",
      "this must be 269: 248\n",
      "VI_indeks: NDVI, NDVI_threshold: 3\n",
      "            None  Predict_Single  Predict_Double\n",
      "0  Actual_Single             159              41\n",
      "1  Actual_Double              17              31\n",
      "\n",
      "count difference is 24\n",
      "acr difference is 962.3965821776367\n",
      "true_double_predicted_single.ExctAcr 1622.880387351114\n",
      "true_single_predicted_double.ExctAcr 2585.2769695287507\n",
      "\n",
      "==================================================================================================\n",
      "this must be 269: 248\n",
      "VI_indeks: NDVI, NDVI_threshold: 4\n",
      "            None  Predict_Single  Predict_Double\n",
      "0  Actual_Single             157              43\n",
      "1  Actual_Double               9              39\n",
      "\n",
      "count difference is 34\n",
      "acr difference is 1973.9842729535007\n",
      "true_double_predicted_single.ExctAcr 996.7353033720248\n",
      "true_single_predicted_double.ExctAcr 2970.7195763255254\n",
      "\n",
      "==================================================================================================\n",
      "this must be 269: 248\n",
      "VI_indeks: NDVI, NDVI_threshold: 5\n",
      "            None  Predict_Single  Predict_Double\n",
      "0  Actual_Single             171              29\n",
      "1  Actual_Double               8              40\n",
      "\n",
      "count difference is 21\n",
      "acr difference is 1474.3239120111764\n",
      "true_double_predicted_single.ExctAcr 731.5374789418868\n",
      "true_single_predicted_double.ExctAcr 2205.861390953063\n",
      "\n",
      "==================================================================================================\n",
      "this must be 269: 248\n",
      "VI_indeks: EVI, NDVI_threshold: 3\n",
      "            None  Predict_Single  Predict_Double\n",
      "0  Actual_Single             155              45\n",
      "1  Actual_Double               8              40\n",
      "\n",
      "count difference is 37\n",
      "acr difference is 1602.8982623109441\n",
      "true_double_predicted_single.ExctAcr 1019.761141106036\n",
      "true_single_predicted_double.ExctAcr 2622.6594034169802\n",
      "\n",
      "==================================================================================================\n",
      "this must be 269: 248\n",
      "VI_indeks: EVI, NDVI_threshold: 4\n",
      "            None  Predict_Single  Predict_Double\n",
      "0  Actual_Single             169              31\n",
      "1  Actual_Double               5              43\n",
      "\n",
      "count difference is 26\n",
      "acr difference is 1387.9449504247782\n",
      "true_double_predicted_single.ExctAcr 479.6505064260888\n",
      "true_single_predicted_double.ExctAcr 1867.5954568508669\n",
      "\n",
      "==================================================================================================\n",
      "this must be 269: 248\n",
      "VI_indeks: EVI, NDVI_threshold: 5\n",
      "            None  Predict_Single  Predict_Double\n",
      "0  Actual_Single             178              22\n",
      "1  Actual_Double               8              40\n",
      "\n",
      "count difference is 14\n",
      "acr difference is 473.1049644158386\n",
      "true_double_predicted_single.ExctAcr 628.7782257221702\n",
      "true_single_predicted_double.ExctAcr 1101.8831901380088\n",
      "\n"
     ]
    }
   ],
   "source": [
    "VI_indeksss = [\"NDVI\", \"EVI\"]\n",
    "NDVI_thresholds = [3, 4, 5]\n",
    "\n",
    "VI_indeks=\"EVI\"\n",
    "NDVI_threshold=3\n",
    "\n",
    "for VI_indeks in VI_indeksss:\n",
    "    for NDVI_threshold  in NDVI_thresholds:\n",
    "        all_data = pd.DataFrame()\n",
    "\n",
    "        for fileName in files_with_3_filters:\n",
    "            if VI_indeks+str(NDVI_threshold) in fileName:\n",
    "                a=pd.read_csv(data_dir + fileName)\n",
    "                a['human_system_start_time'] = pd.to_datetime(a['human_system_start_time'])\n",
    "                curr_year = int(fileName.split(\"_\")[2][-4:])\n",
    "                a = a[a['human_system_start_time'].dt.year == curr_year].copy()\n",
    "                a = a[[\"ID\", \"season_count\"]]\n",
    "\n",
    "                all_data=pd.concat([all_data, a])\n",
    "\n",
    "        all_data = all_data[all_data.ID.isin(list(ground_truth_labels_test.ID.unique()))].copy()\n",
    "        all_data.drop_duplicates(inplace=True)\n",
    "        all_data.reset_index(drop=True, inplace=True)\n",
    "        print (\"==================================================================================================\")\n",
    "        single_season=all_data[all_data.season_count<2]\n",
    "        two_seasons=all_data[all_data.season_count>=2]\n",
    "        print (\"this must be 269:\", str(len(single_season)+len(two_seasons)))\n",
    "        \n",
    "        evalHelp = pd.merge(ground_truth_labels_test, all_data, on=['ID'], how='left')\n",
    "        true_single_predicted_single = evalHelp[evalHelp.Vote==1].copy()\n",
    "        true_single_predicted_single = true_single_predicted_single[true_single_predicted_single.season_count<2]\n",
    "\n",
    "\n",
    "        true_double_predicted_double = evalHelp[evalHelp.Vote>=2].copy()\n",
    "        true_double_predicted_double = true_double_predicted_double[true_double_predicted_double.season_count>=2]\n",
    "\n",
    "        true_double_predicted_single=evalHelp[evalHelp.Vote==2].copy()\n",
    "        true_double_predicted_single = true_double_predicted_single[true_double_predicted_single.season_count<2]\n",
    "\n",
    "        true_single_predicted_double=evalHelp[evalHelp.Vote==1].copy()\n",
    "        true_single_predicted_double = true_single_predicted_double[true_single_predicted_double.season_count>=2]\n",
    "\n",
    "\n",
    "        balanced_confus_tbl_test = pd.DataFrame(columns=['None', 'Predict_Single', 'Predict_Double'], \n",
    "                                                index=range(2))\n",
    "        balanced_confus_tbl_test.loc[0, 'None'] = 'Actual_Single'\n",
    "        balanced_confus_tbl_test.loc[1, 'None'] = 'Actual_Double'\n",
    "        balanced_confus_tbl_test['Predict_Single']=0\n",
    "        balanced_confus_tbl_test['Predict_Double']=0\n",
    "\n",
    "        balanced_confus_tbl_test.loc[0, \"Predict_Single\"]=len(true_single_predicted_single)\n",
    "        balanced_confus_tbl_test.loc[0, \"Predict_Double\"]=len(true_single_predicted_double)\n",
    "        balanced_confus_tbl_test.loc[1, \"Predict_Single\"]=len(true_double_predicted_single)\n",
    "        balanced_confus_tbl_test.loc[1, \"Predict_Double\"]=len(true_double_predicted_double)\n",
    "        \n",
    "        print (\"VI_indeks: \" + VI_indeks + \", NDVI_threshold: \" + str(NDVI_threshold))\n",
    "        print (balanced_confus_tbl_test)\n",
    "        print (\"\")\n",
    "        _dc = np.abs(balanced_confus_tbl_test.loc[0, \"Predict_Double\"]-balanced_confus_tbl_test.loc[1, \"Predict_Single\"])\n",
    "        print (\"count difference is \" + str(_dc))\n",
    "        acr_diff=np.abs(true_double_predicted_single.ExctAcr.sum()-true_single_predicted_double.ExctAcr.sum())\n",
    "        print (\"acr difference is \"+str(acr_diff))\n",
    "        print (\"true_double_predicted_single.ExctAcr\", true_double_predicted_single.ExctAcr.sum())\n",
    "        print (\"true_single_predicted_double.ExctAcr\", true_single_predicted_double.ExctAcr.sum())\n",
    "        print ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da9011c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7a58e5b6",
   "metadata": {},
   "source": [
    "# Sentinel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "107c3bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_dir = \"/Users/hn/Documents/01_research_data/NASA/Sentinel/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b64521b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c7001df4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(248, 9)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ground_truth_labels=ground_truth_labels[ground_truth_labels.county!=\"Walla Walla\"]\n",
    "ground_truth_labels_test = ground_truth_labels[ground_truth_labels.ID.isin(list(testset.ID))]\n",
    "ground_truth_labels_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ad890048",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fileNames = [\"extended_all_fields_seasonCounts_noFilter_SEOS3\", \"extended_all_fields_seasonCounts_noFilter_SEOS4\",\n",
    "#              \"extended_all_fields_seasonCounts_noFilter_SEOS5\"]\n",
    "# sentinel_data=pd.DataFrame()\n",
    "# for a_file in fileNames:\n",
    "#     a=pd.read_csv(sent_dir+\"05_01_allFields_SeasonCounts/\" + a_file+\".csv\")\n",
    "#     a=a[a.SG_params==73]\n",
    "#     sentinel_data=pd.concat([sentinel_data, a])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f2ef6274",
   "metadata": {},
   "outputs": [],
   "source": [
    "VI_indeksss = [\"NDVI\", \"EVI\"]\n",
    "years=[2016, 2017, 2018]\n",
    "NDVI_thresholds = [3, 4, 5]\n",
    "Name_pattern = \"win7_Order3\"\n",
    "folder_prePattern = \"2Yrs_tbl_reg_fineGranular_SOS\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f20d69d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "VI_indeks=\"NDVI\"\n",
    "NDVI_threshold=3\n",
    "all_data=pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5cd25abf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================================================================\n",
      "this must be 248: 248\n",
      "VI_indeks: NDVI, NDVI_threshold: 3\n",
      "            None  Predict_Single  Predict_Double\n",
      "0  Actual_Single             176              24\n",
      "1  Actual_Double              18              30\n",
      "\n",
      "count difference is 6\n",
      "acr difference is 278.1679991898775\n",
      "true_double_predicted_single.ExctAcr 1777.304625509689\n",
      "true_single_predicted_double.ExctAcr 1499.1366263198115\n",
      "\n",
      "==================================================================================================\n",
      "this must be 248: 248\n",
      "VI_indeks: NDVI, NDVI_threshold: 4\n",
      "            None  Predict_Single  Predict_Double\n",
      "0  Actual_Single             183              17\n",
      "1  Actual_Double              11              37\n",
      "\n",
      "count difference is 6\n",
      "acr difference is 26.924727617746385\n",
      "true_double_predicted_single.ExctAcr 1022.8747940444512\n",
      "true_single_predicted_double.ExctAcr 995.9500664267048\n",
      "\n",
      "==================================================================================================\n",
      "this must be 248: 248\n",
      "VI_indeks: NDVI, NDVI_threshold: 5\n",
      "            None  Predict_Single  Predict_Double\n",
      "0  Actual_Single             182              18\n",
      "1  Actual_Double              12              36\n",
      "\n",
      "count difference is 6\n",
      "acr difference is 156.17385724187045\n",
      "true_double_predicted_single.ExctAcr 1141.1396135188918\n",
      "true_single_predicted_double.ExctAcr 984.9657562770213\n",
      "\n",
      "==================================================================================================\n",
      "this must be 248: 248\n",
      "VI_indeks: EVI, NDVI_threshold: 3\n",
      "            None  Predict_Single  Predict_Double\n",
      "0  Actual_Single             186              14\n",
      "1  Actual_Double              16              32\n",
      "\n",
      "count difference is 2\n",
      "acr difference is 770.3689857132612\n",
      "true_double_predicted_single.ExctAcr 1657.6985119369683\n",
      "true_single_predicted_double.ExctAcr 887.3295262237071\n",
      "\n",
      "==================================================================================================\n",
      "this must be 248: 248\n",
      "VI_indeks: EVI, NDVI_threshold: 4\n",
      "            None  Predict_Single  Predict_Double\n",
      "0  Actual_Single             184              16\n",
      "1  Actual_Double              13              35\n",
      "\n",
      "count difference is 3\n",
      "acr difference is 234.41777328296416\n",
      "true_double_predicted_single.ExctAcr 1135.0662921531086\n",
      "true_single_predicted_double.ExctAcr 900.6485188701445\n",
      "\n",
      "==================================================================================================\n",
      "this must be 248: 248\n",
      "VI_indeks: EVI, NDVI_threshold: 5\n",
      "            None  Predict_Single  Predict_Double\n",
      "0  Actual_Single             186              14\n",
      "1  Actual_Double              13              35\n",
      "\n",
      "count difference is 1\n",
      "acr difference is 355.1658141743792\n",
      "true_double_predicted_single.ExctAcr 1210.4419716230436\n",
      "true_single_predicted_double.ExctAcr 855.2761574486644\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for VI_indeks in VI_indeksss:\n",
    "    for NDVI_threshold in NDVI_thresholds:\n",
    "        all_data=pd.DataFrame()\n",
    "        for year in years:\n",
    "            folder_name = folder_prePattern+str(NDVI_threshold)+\"_EOS\"+str(NDVI_threshold)\n",
    "            data_dir = sent_dir+folder_name+\"/\"\n",
    "            file_list = os.listdir(data_dir)\n",
    "            file_list_SG73 = [x for x in file_list if Name_pattern in x]\n",
    "            file_list_SG73 = [x for x in file_list_SG73 if VI_indeks in x]\n",
    "\n",
    "            if year==2016:\n",
    "                cnty1_names = [x for x in file_list_SG73 if \"Adams_2016\" in x]\n",
    "                cnty2_names = [x for x in file_list_SG73 if \"Benton_2016\" in x]\n",
    "                finalFileNames = cnty1_names+cnty2_names\n",
    "            elif year==2017:\n",
    "                finalFileNames= [x for x in file_list_SG73 if \"Grant_2017\" in x]\n",
    "            elif year==2018:\n",
    "                cnty1_names = [x for x in file_list_SG73 if \"Franklin_2018\" in x]\n",
    "                cnty2_names = [x for x in file_list_SG73 if \"Yakima_2018\" in x]\n",
    "                finalFileNames = cnty1_names+cnty2_names\n",
    "\n",
    "            # print(VI_indeks, year, NDVI_threshold, finalFileNames)\n",
    "            aIndeks_all_data=pd.DataFrame()\n",
    "            for a_file in finalFileNames:\n",
    "                a=pd.read_csv(data_dir+a_file)\n",
    "                a['human_system_start_time'] = pd.to_datetime(a['human_system_start_time'])\n",
    "                aIndeks_all_data=pd.concat([aIndeks_all_data, a])\n",
    "            all_data=pd.concat([all_data, aIndeks_all_data])\n",
    "            all_data = all_data[all_data.ID.isin(list(ground_truth_labels_test.ID.unique()))].copy()\n",
    "            all_data=all_data[[\"ID\", \"season_count\"]]\n",
    "            all_data.drop_duplicates(inplace=True)\n",
    "            all_data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "        print (\"==================================================================================================\")\n",
    "        single_season=all_data[all_data.season_count<2]\n",
    "        two_seasons=all_data[all_data.season_count>=2]\n",
    "        print (\"this must be 248:\", str(len(single_season)+len(two_seasons)))\n",
    "        \n",
    "        evalHelp = pd.merge(ground_truth_labels_test, all_data, on=['ID'], how='left')\n",
    "        true_single_predicted_single = evalHelp[evalHelp.Vote==1].copy()\n",
    "        true_single_predicted_single = true_single_predicted_single[true_single_predicted_single.season_count<2]\n",
    "\n",
    "\n",
    "        true_double_predicted_double = evalHelp[evalHelp.Vote>=2].copy()\n",
    "        true_double_predicted_double = true_double_predicted_double[true_double_predicted_double.season_count>=2]\n",
    "\n",
    "        true_double_predicted_single=evalHelp[evalHelp.Vote==2].copy()\n",
    "        true_double_predicted_single = true_double_predicted_single[true_double_predicted_single.season_count<2]\n",
    "\n",
    "        true_single_predicted_double=evalHelp[evalHelp.Vote==1].copy()\n",
    "        true_single_predicted_double = true_single_predicted_double[true_single_predicted_double.season_count>=2]\n",
    "\n",
    "\n",
    "        balanced_confus_tbl_test = pd.DataFrame(columns=['None', 'Predict_Single', 'Predict_Double'], \n",
    "                                                index=range(2))\n",
    "        balanced_confus_tbl_test.loc[0, 'None'] = 'Actual_Single'\n",
    "        balanced_confus_tbl_test.loc[1, 'None'] = 'Actual_Double'\n",
    "        balanced_confus_tbl_test['Predict_Single']=0\n",
    "        balanced_confus_tbl_test['Predict_Double']=0\n",
    "\n",
    "        balanced_confus_tbl_test.loc[0, \"Predict_Single\"]=len(true_single_predicted_single)\n",
    "        balanced_confus_tbl_test.loc[0, \"Predict_Double\"]=len(true_single_predicted_double)\n",
    "        balanced_confus_tbl_test.loc[1, \"Predict_Single\"]=len(true_double_predicted_single)\n",
    "        balanced_confus_tbl_test.loc[1, \"Predict_Double\"]=len(true_double_predicted_double)\n",
    "\n",
    "        print (\"VI_indeks: \" + VI_indeks + \", NDVI_threshold: \" + str(NDVI_threshold))\n",
    "        print (balanced_confus_tbl_test)\n",
    "        print (\"\")\n",
    "        _dc = np.abs(balanced_confus_tbl_test.loc[0, \"Predict_Double\"]-balanced_confus_tbl_test.loc[1, \"Predict_Single\"])\n",
    "        print (\"count difference is \" + str(_dc))\n",
    "        acr_diff=np.abs(true_double_predicted_single.ExctAcr.sum()-true_single_predicted_double.ExctAcr.sum())\n",
    "        print (\"acr difference is \"+str(acr_diff))\n",
    "        print (\"true_double_predicted_single.ExctAcr\", true_double_predicted_single.ExctAcr.sum())\n",
    "        print (\"true_single_predicted_double.ExctAcr\", true_single_predicted_double.ExctAcr.sum())\n",
    "        print ()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1fac5174",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(397, 25)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "id": "e1a54e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "adam_2016=pd.read_csv(data_dir+\"Adams_2016_regular_EVI_SG_win7_Order3.csv\")\n",
    "adam_2017=pd.read_csv(data_dir+\"Adams_2017_regular_EVI_SG_win7_Order3.csv\")\n",
    "adam_2018=pd.read_csv(data_dir+\"Adams_2018_regular_EVI_SG_win7_Order3.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "id": "c96a8cd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Acres</th>\n",
       "      <th>county</th>\n",
       "      <th>CropGrp</th>\n",
       "      <th>CropTyp</th>\n",
       "      <th>DataSrc</th>\n",
       "      <th>ExctAcr</th>\n",
       "      <th>IntlSrD</th>\n",
       "      <th>Irrigtn</th>\n",
       "      <th>LstSrvD</th>\n",
       "      <th>...</th>\n",
       "      <th>image_year</th>\n",
       "      <th>SF_year</th>\n",
       "      <th>doy</th>\n",
       "      <th>EVI</th>\n",
       "      <th>human_system_start_time</th>\n",
       "      <th>Date</th>\n",
       "      <th>EVI_ratio</th>\n",
       "      <th>SOS</th>\n",
       "      <th>EOS</th>\n",
       "      <th>season_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1762</th>\n",
       "      <td>102173_WSDA_SF_2018</td>\n",
       "      <td>4</td>\n",
       "      <td>Franklin</td>\n",
       "      <td>Hay/Silage</td>\n",
       "      <td>alfalfa hay</td>\n",
       "      <td>wsda</td>\n",
       "      <td>3.887527</td>\n",
       "      <td>2005/08/15 00:00:00</td>\n",
       "      <td>wheel line</td>\n",
       "      <td>2018/04/11 00:00:00</td>\n",
       "      <td>...</td>\n",
       "      <td>2018</td>\n",
       "      <td>2018</td>\n",
       "      <td>75</td>\n",
       "      <td>0.627292</td>\n",
       "      <td>2018-03-16</td>\n",
       "      <td>2018-03-16 00:00:00</td>\n",
       "      <td>0.531956</td>\n",
       "      <td>0.627292</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1763</th>\n",
       "      <td>102173_WSDA_SF_2018</td>\n",
       "      <td>4</td>\n",
       "      <td>Franklin</td>\n",
       "      <td>Hay/Silage</td>\n",
       "      <td>alfalfa hay</td>\n",
       "      <td>wsda</td>\n",
       "      <td>3.887527</td>\n",
       "      <td>2005/08/15 00:00:00</td>\n",
       "      <td>wheel line</td>\n",
       "      <td>2018/04/11 00:00:00</td>\n",
       "      <td>...</td>\n",
       "      <td>2018</td>\n",
       "      <td>2018</td>\n",
       "      <td>124</td>\n",
       "      <td>0.605709</td>\n",
       "      <td>2018-05-04</td>\n",
       "      <td>2018-05-04 00:00:00</td>\n",
       "      <td>0.486745</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.605709</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1764</th>\n",
       "      <td>102173_WSDA_SF_2018</td>\n",
       "      <td>4</td>\n",
       "      <td>Franklin</td>\n",
       "      <td>Hay/Silage</td>\n",
       "      <td>alfalfa hay</td>\n",
       "      <td>wsda</td>\n",
       "      <td>3.887527</td>\n",
       "      <td>2005/08/15 00:00:00</td>\n",
       "      <td>wheel line</td>\n",
       "      <td>2018/04/11 00:00:00</td>\n",
       "      <td>...</td>\n",
       "      <td>2018</td>\n",
       "      <td>2018</td>\n",
       "      <td>136</td>\n",
       "      <td>0.623922</td>\n",
       "      <td>2018-05-16</td>\n",
       "      <td>2018-05-16 00:00:00</td>\n",
       "      <td>0.524896</td>\n",
       "      <td>0.623922</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1765</th>\n",
       "      <td>102173_WSDA_SF_2018</td>\n",
       "      <td>4</td>\n",
       "      <td>Franklin</td>\n",
       "      <td>Hay/Silage</td>\n",
       "      <td>alfalfa hay</td>\n",
       "      <td>wsda</td>\n",
       "      <td>3.887527</td>\n",
       "      <td>2005/08/15 00:00:00</td>\n",
       "      <td>wheel line</td>\n",
       "      <td>2018/04/11 00:00:00</td>\n",
       "      <td>...</td>\n",
       "      <td>2018</td>\n",
       "      <td>2018</td>\n",
       "      <td>253</td>\n",
       "      <td>0.610363</td>\n",
       "      <td>2018-09-10</td>\n",
       "      <td>2018-09-10 00:00:00</td>\n",
       "      <td>0.496493</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.610363</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1766</th>\n",
       "      <td>102173_WSDA_SF_2018</td>\n",
       "      <td>4</td>\n",
       "      <td>Franklin</td>\n",
       "      <td>Hay/Silage</td>\n",
       "      <td>alfalfa hay</td>\n",
       "      <td>wsda</td>\n",
       "      <td>3.887527</td>\n",
       "      <td>2005/08/15 00:00:00</td>\n",
       "      <td>wheel line</td>\n",
       "      <td>2018/04/11 00:00:00</td>\n",
       "      <td>...</td>\n",
       "      <td>2018</td>\n",
       "      <td>2018</td>\n",
       "      <td>278</td>\n",
       "      <td>0.612874</td>\n",
       "      <td>2018-10-05</td>\n",
       "      <td>2018-10-05 00:00:00</td>\n",
       "      <td>0.501753</td>\n",
       "      <td>0.612874</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1767</th>\n",
       "      <td>102173_WSDA_SF_2018</td>\n",
       "      <td>4</td>\n",
       "      <td>Franklin</td>\n",
       "      <td>Hay/Silage</td>\n",
       "      <td>alfalfa hay</td>\n",
       "      <td>wsda</td>\n",
       "      <td>3.887527</td>\n",
       "      <td>2005/08/15 00:00:00</td>\n",
       "      <td>wheel line</td>\n",
       "      <td>2018/04/11 00:00:00</td>\n",
       "      <td>...</td>\n",
       "      <td>2018</td>\n",
       "      <td>2018</td>\n",
       "      <td>324</td>\n",
       "      <td>0.608222</td>\n",
       "      <td>2018-11-20</td>\n",
       "      <td>2018-11-20 00:00:00</td>\n",
       "      <td>0.492008</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.608222</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       ID  Acres    county     CropGrp      CropTyp DataSrc  \\\n",
       "1762  102173_WSDA_SF_2018      4  Franklin  Hay/Silage  alfalfa hay    wsda   \n",
       "1763  102173_WSDA_SF_2018      4  Franklin  Hay/Silage  alfalfa hay    wsda   \n",
       "1764  102173_WSDA_SF_2018      4  Franklin  Hay/Silage  alfalfa hay    wsda   \n",
       "1765  102173_WSDA_SF_2018      4  Franklin  Hay/Silage  alfalfa hay    wsda   \n",
       "1766  102173_WSDA_SF_2018      4  Franklin  Hay/Silage  alfalfa hay    wsda   \n",
       "1767  102173_WSDA_SF_2018      4  Franklin  Hay/Silage  alfalfa hay    wsda   \n",
       "\n",
       "       ExctAcr              IntlSrD     Irrigtn              LstSrvD  ...  \\\n",
       "1762  3.887527  2005/08/15 00:00:00  wheel line  2018/04/11 00:00:00  ...   \n",
       "1763  3.887527  2005/08/15 00:00:00  wheel line  2018/04/11 00:00:00  ...   \n",
       "1764  3.887527  2005/08/15 00:00:00  wheel line  2018/04/11 00:00:00  ...   \n",
       "1765  3.887527  2005/08/15 00:00:00  wheel line  2018/04/11 00:00:00  ...   \n",
       "1766  3.887527  2005/08/15 00:00:00  wheel line  2018/04/11 00:00:00  ...   \n",
       "1767  3.887527  2005/08/15 00:00:00  wheel line  2018/04/11 00:00:00  ...   \n",
       "\n",
       "     image_year SF_year  doy       EVI human_system_start_time  \\\n",
       "1762       2018    2018   75  0.627292              2018-03-16   \n",
       "1763       2018    2018  124  0.605709              2018-05-04   \n",
       "1764       2018    2018  136  0.623922              2018-05-16   \n",
       "1765       2018    2018  253  0.610363              2018-09-10   \n",
       "1766       2018    2018  278  0.612874              2018-10-05   \n",
       "1767       2018    2018  324  0.608222              2018-11-20   \n",
       "\n",
       "                     Date  EVI_ratio       SOS       EOS season_count  \n",
       "1762  2018-03-16 00:00:00   0.531956  0.627292  0.000000            3  \n",
       "1763  2018-05-04 00:00:00   0.486745  0.000000  0.605709            3  \n",
       "1764  2018-05-16 00:00:00   0.524896  0.623922  0.000000            3  \n",
       "1765  2018-09-10 00:00:00   0.496493  0.000000  0.610363            3  \n",
       "1766  2018-10-05 00:00:00   0.501753  0.612874  0.000000            3  \n",
       "1767  2018-11-20 00:00:00   0.492008  0.000000  0.608222            3  \n",
       "\n",
       "[6 rows x 25 columns]"
      ]
     },
     "execution_count": 401,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data[all_data.ID==\"102173_WSDA_SF_2018\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7f776a32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Adams', 'Benton', 'Grant', 'Franklin', 'Yakima'], dtype=object)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data.county.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "id": "cafc228e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "248"
      ]
     },
     "execution_count": 408,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data = all_data[all_data.ID.isin(list(ground_truth_labels_test.ID.unique()))].copy()\n",
    "len(all_data.ID.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6c525a70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2018], dtype=int64)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Adams = all_data[all_data.county==\"Franklin\"]\n",
    "Adams['human_system_start_time'].dt.year.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6715887f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83794d67",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
