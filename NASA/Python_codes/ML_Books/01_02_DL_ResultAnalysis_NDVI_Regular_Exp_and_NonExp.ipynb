{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "272d28c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import date\n",
    "from random import seed\n",
    "from random import random\n",
    "\n",
    "import time\n",
    "import scipy, scipy.signal\n",
    "import os, os.path\n",
    "import shutil\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pylab import imshow\n",
    "from matplotlib.image import imread\n",
    "# vgg16 model used for transfer learning on the dogs and cats dataset\n",
    "from matplotlib import pyplot\n",
    "# from keras.utils import to_categorical\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "import tensorflow as tf\n",
    "# from keras.optimizers import SGD\n",
    "\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "\n",
    "# from keras.optimizers import gradient_descent_v2\n",
    "# SGD = gradient_descent_v2.SGD(...)\n",
    "\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import h5py\n",
    "import sys\n",
    "sys.path.append('/Users/hn/Documents/00_GitHub/Ag/NASA/Python_codes/')\n",
    "import NASA_core as nc\n",
    "# import NASA_plot_core as rcp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea721c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import load_img\n",
    "from tensorflow.keras.utils import img_to_array\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cfcfed8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "VI_idx = \"NDVI\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ff3a86",
   "metadata": {},
   "source": [
    "# Make Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2dce34aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-12 13:39:30.554159: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "model_dir = \"/Users/hn/Documents/01_research_data/NASA/ML_Models/\"\n",
    "model = load_model(model_dir + \"01_TL_SingleDouble\" + VI_idx + \"_regular_train80.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "746a83c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b6ff828",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and prepare the image\n",
    "def load_image(filename):\n",
    "    # load the image\n",
    "    img = load_img(filename, target_size=(224, 224))\n",
    "    # convert to array\n",
    "    img = img_to_array(img)\n",
    "    # reshape into a single sample with 3 channels\n",
    "    img = img.reshape(1, 224, 224, 3)\n",
    "    # center pixel data\n",
    "    img = img.astype('float32')\n",
    "    img = img - [123.68, 116.779, 103.939]\n",
    "    return img\n",
    "\n",
    "# # load an image and predict the class\n",
    "# def run_example():\n",
    "#     # load the image\n",
    "#     test_dir = \"/Users/hn/Documents/01_research_data/NASA/ML_data/limitCrops_nonExpert_images_\" + VI_idx + \"/\"\n",
    "#     img = load_image(test_dir+'double_101682_WSDA_SF_2018.jpg')\n",
    "#     # load model\n",
    "#     model_dir = \"/Users/hn/Documents/01_research_data/NASA/ML_Models/\"\n",
    "#     model = load_model(model_dir + '01_TL_SingleDouble.h5')\n",
    "#     # predict the class\n",
    "#     result = model.predict(img)\n",
    "#     print(result[0])\n",
    "\n",
    "# entry point, run the example\n",
    "# run_example()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cffade2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f4175e23",
   "metadata": {},
   "source": [
    "# Test Phase\n",
    "\n",
    "#### Test set from expert labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "79898dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set_dir = \"/Users/hn/Documents/01_research_data/NASA/ML_data/\"\n",
    "ground_truth_labels = pd.read_csv(training_set_dir+\"train_labels.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "41cd4c21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(269, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>human_predict</th>\n",
       "      <th>prob_single</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>single_111436_WSDA_SF_2017.jpg</td>\n",
       "      <td>single</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>single_38745_WSDA_SF_2018.jpg</td>\n",
       "      <td>single</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         filename human_predict  prob_single\n",
       "0  single_111436_WSDA_SF_2017.jpg        single         -1.0\n",
       "1   single_38745_WSDA_SF_2018.jpg        single         -1.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expert_test_dir = \"/Users/hn/Documents/01_research_data/NASA/ML_data/regular_train_images_\" + VI_idx + \"/test20/\"\n",
    "\n",
    "test_filenames = os.listdir(expert_test_dir)\n",
    "expert_test_df = pd.DataFrame({\n",
    "                               'filename': test_filenames\n",
    "                                    })\n",
    "nb_samples = expert_test_df.shape[0]\n",
    "\n",
    "expert_test_df[\"human_predict\"] = expert_test_df.filename.str.split(\"_\", expand=True)[0]\n",
    "expert_test_df[\"prob_single\"]=-1.0\n",
    "print (expert_test_df.shape)\n",
    "expert_test_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd16b2fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e9e72f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 204ms/step\n",
      "[2.4672556e-08]\n"
     ]
    }
   ],
   "source": [
    "# load an image and predict the class\n",
    "def run_example():\n",
    "    # load the image\n",
    "    test_dir = experts_test_dir = \"/Users/hn/Documents/01_research_data/NASA/ML_data/\" + \\\n",
    "                                  \"/regular_train_images_\" + VI_idx + \"/test20/\"\n",
    "    \n",
    "    img = load_image(test_dir+'double_1624_WSDA_SF_2016.jpg')\n",
    "    # load model\n",
    "    model_dir = \"/Users/hn/Documents/01_research_data/NASA/ML_Models/\"\n",
    "    model = load_model(model_dir + \"01_TL_SingleDouble\" + VI_idx +\"_regular_train80.h5\")\n",
    "    result = model.predict(img)\n",
    "    print(result[0])\n",
    "\n",
    "# entry point, run the example\n",
    "run_example()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5327fd3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ab4bbfdc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# We have done this once before. So, commented out here. and read below.\n",
    "\n",
    "# for idx in expert_test_df.index:\n",
    "#     img = load_image(expert_test_dir + expert_test_df.loc[idx, 'filename'])\n",
    "#     expert_test_df.loc[idx, 'prob_single'] = model.predict(img, verbose=False)[0][0]\n",
    "\n",
    "\n",
    "# for prob in [0.3, 0.4, 0.5, 0.6, 0.7]:\n",
    "#     colName = \"prob_point\"+str(prob)[2:]\n",
    "#     expert_test_df.loc[expert_test_df.prob_single<prob, colName] = 'double'\n",
    "#     expert_test_df.loc[expert_test_df.prob_single>=prob, colName] = 'single'\n",
    "\n",
    "# out_dir = \"/Users/hn/Documents/01_research_data/NASA/ML_data/01_transfer_learning_result/\"\n",
    "# os.makedirs(out_dir, exist_ok=True)\n",
    "# out_name = out_dir + \"01_regular_TL_Expert_testSet_predictions_\" + VI_idx + \".csv\"\n",
    "# expert_test_df.to_csv(out_name, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "45dc8a03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>human_predict</th>\n",
       "      <th>prob_single</th>\n",
       "      <th>prob_point3</th>\n",
       "      <th>prob_point4</th>\n",
       "      <th>prob_point5</th>\n",
       "      <th>prob_point6</th>\n",
       "      <th>prob_point7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>single_111436_WSDA_SF_2017.jpg</td>\n",
       "      <td>single</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>single</td>\n",
       "      <td>single</td>\n",
       "      <td>single</td>\n",
       "      <td>single</td>\n",
       "      <td>single</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>single_38745_WSDA_SF_2018.jpg</td>\n",
       "      <td>single</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>single</td>\n",
       "      <td>single</td>\n",
       "      <td>single</td>\n",
       "      <td>single</td>\n",
       "      <td>single</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         filename human_predict  prob_single prob_point3  \\\n",
       "0  single_111436_WSDA_SF_2017.jpg        single     1.000000      single   \n",
       "1   single_38745_WSDA_SF_2018.jpg        single     0.999998      single   \n",
       "\n",
       "  prob_point4 prob_point5 prob_point6 prob_point7  \n",
       "0      single      single      single      single  \n",
       "1      single      single      single      single  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_dir = \"/Users/hn/Documents/01_research_data/NASA/ML_data/01_transfer_learning_result/\"\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "expert_test_df = pd.read_csv(out_dir + \"01_regular_TL_Expert_testSet_predictions_\" + VI_idx + \".csv\")\n",
    "expert_test_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cf42b288",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ii in [3, 4, 5, 6, 7]:\n",
    "    curr_prob = \"prob_point\"+str(ii)\n",
    "    curr_pred_type = \"predType_point\" + str(ii)\n",
    "    expert_test_df[curr_pred_type]=\"a\"\n",
    "    for idx in expert_test_df.index:\n",
    "        if expert_test_df.loc[idx, \"human_predict\"]==expert_test_df.loc[idx, curr_prob]==\"single\":\n",
    "            expert_test_df.loc[idx, curr_pred_type]=\"True Single\"\n",
    "        elif expert_test_df.loc[idx, \"human_predict\"]==expert_test_df.loc[idx, curr_prob]==\"double\":\n",
    "            expert_test_df.loc[idx, curr_pred_type]=\"True Double\"\n",
    "        elif expert_test_df.loc[idx, \"human_predict\"]==\"double\" and expert_test_df.loc[idx, curr_prob]==\"single\":\n",
    "            expert_test_df.loc[idx, curr_pred_type]=\"False Single\"\n",
    "        elif expert_test_df.loc[idx, \"human_predict\"]==\"single\" and expert_test_df.loc[idx, curr_prob]==\"double\":\n",
    "            expert_test_df.loc[idx, curr_pred_type]=\"False Double\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e2d5c8c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predType_point3</th>\n",
       "      <th>predType_point4</th>\n",
       "      <th>predType_point5</th>\n",
       "      <th>predType_point6</th>\n",
       "      <th>predType_point7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True Single</td>\n",
       "      <td>True Single</td>\n",
       "      <td>True Single</td>\n",
       "      <td>True Single</td>\n",
       "      <td>True Single</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True Single</td>\n",
       "      <td>True Single</td>\n",
       "      <td>True Single</td>\n",
       "      <td>True Single</td>\n",
       "      <td>True Single</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  predType_point3 predType_point4 predType_point5 predType_point6  \\\n",
       "0     True Single     True Single     True Single     True Single   \n",
       "1     True Single     True Single     True Single     True Single   \n",
       "\n",
       "  predType_point7  \n",
       "0     True Single  \n",
       "1     True Single  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "needed_cols = [\"predType_point3\", \"predType_point4\", \n",
    "               \"predType_point5\", \n",
    "               \"predType_point6\", \"predType_point7\"]\n",
    "expert_test_df_trimmed = expert_test_df[needed_cols].copy()\n",
    "expert_test_df_trimmed.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1a874069",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predType_point3</th>\n",
       "      <th>predType_point4</th>\n",
       "      <th>predType_point5</th>\n",
       "      <th>predType_point6</th>\n",
       "      <th>predType_point7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>True Single</th>\n",
       "      <td>215</td>\n",
       "      <td>215</td>\n",
       "      <td>215</td>\n",
       "      <td>214</td>\n",
       "      <td>212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True Double</th>\n",
       "      <td>45</td>\n",
       "      <td>46</td>\n",
       "      <td>46</td>\n",
       "      <td>47</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>False Double</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>False Single</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              predType_point3  predType_point4  predType_point5  \\\n",
       "True Single               215              215              215   \n",
       "True Double                45               46               46   \n",
       "False Double                4                4                4   \n",
       "False Single                5                4                4   \n",
       "\n",
       "              predType_point6  predType_point7  \n",
       "True Single               214              212  \n",
       "True Double                47               47  \n",
       "False Double                5                7  \n",
       "False Single                3                3  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_rows=[\"True Single\", \"True Double\", \"False Double\", \"False Single\"]\n",
    "TFR=pd.DataFrame(index=index_rows)\n",
    "for col in expert_test_df_trimmed.columns:\n",
    "    curr=pd.DataFrame(expert_test_df_trimmed[col].value_counts())\n",
    "    TFR=pd.merge(TFR, curr, left_index=True, right_index=True, how=\"left\")\n",
    "TFR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bc244708",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = \"/Users/hn/Documents/01_research_data/NASA/ML_data/01_transfer_learning_result/\"\n",
    "out_name = out_dir + \"01_regular_TL_expert_\" + VI_idx + \"_count_TFPR.csv\"\n",
    "TFR.to_csv(out_name, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "317cbdac",
   "metadata": {},
   "outputs": [],
   "source": [
    "expert_test_df[\"ID\"] = expert_test_df.filename.str.split(\"_\", expand=True)[1]+ \"_\" + \\\n",
    "                       expert_test_df.filename.str.split(\"_\", expand=True)[2]+ \"_\" + \\\n",
    "                       expert_test_df.filename.str.split(\"_\", expand=True)[3]+ \"_\" + \\\n",
    "                       expert_test_df.filename.str.split(\"_\", expand=True)[4].str.split(\".\", expand=True)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8150808e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6340, 8)\n",
      "(3539, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>CropTyp</th>\n",
       "      <th>Irrigtn</th>\n",
       "      <th>DataSrc</th>\n",
       "      <th>Acres</th>\n",
       "      <th>ExctAcr</th>\n",
       "      <th>LstSrvD</th>\n",
       "      <th>county</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100010_WSDA_SF_2017</td>\n",
       "      <td>alfalfa hay</td>\n",
       "      <td>center pivot</td>\n",
       "      <td>wsda</td>\n",
       "      <td>34</td>\n",
       "      <td>34.310305</td>\n",
       "      <td>2017/09/12</td>\n",
       "      <td>Grant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100204_WSDA_SF_2017</td>\n",
       "      <td>alfalfa hay</td>\n",
       "      <td>center pivot</td>\n",
       "      <td>wsda</td>\n",
       "      <td>62</td>\n",
       "      <td>61.826535</td>\n",
       "      <td>2017/08/09</td>\n",
       "      <td>Grant</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    ID      CropTyp       Irrigtn DataSrc  Acres    ExctAcr  \\\n",
       "0  100010_WSDA_SF_2017  alfalfa hay  center pivot    wsda     34  34.310305   \n",
       "1  100204_WSDA_SF_2017  alfalfa hay  center pivot    wsda     62  61.826535   \n",
       "\n",
       "      LstSrvD county  \n",
       "0  2017/09/12  Grant  \n",
       "1  2017/08/09  Grant  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_dir = \"/Users/hn/Documents/01_research_data/NASA/parameters/\"\n",
    "meta = pd.read_csv(meta_dir+\"evaluation_set.csv\")\n",
    "meta_moreThan10Acr=meta[meta.ExctAcr>10]\n",
    "print (meta.shape)\n",
    "print (meta_moreThan10Acr.shape)\n",
    "meta.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c3b91643",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>human_predict</th>\n",
       "      <th>prob_single</th>\n",
       "      <th>prob_point3</th>\n",
       "      <th>prob_point4</th>\n",
       "      <th>prob_point5</th>\n",
       "      <th>prob_point6</th>\n",
       "      <th>prob_point7</th>\n",
       "      <th>predType_point3</th>\n",
       "      <th>predType_point4</th>\n",
       "      <th>...</th>\n",
       "      <th>predType_point6</th>\n",
       "      <th>predType_point7</th>\n",
       "      <th>ID</th>\n",
       "      <th>CropTyp</th>\n",
       "      <th>Irrigtn</th>\n",
       "      <th>DataSrc</th>\n",
       "      <th>Acres</th>\n",
       "      <th>ExctAcr</th>\n",
       "      <th>LstSrvD</th>\n",
       "      <th>county</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>single_111436_WSDA_SF_2017.jpg</td>\n",
       "      <td>single</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>single</td>\n",
       "      <td>single</td>\n",
       "      <td>single</td>\n",
       "      <td>single</td>\n",
       "      <td>single</td>\n",
       "      <td>True Single</td>\n",
       "      <td>True Single</td>\n",
       "      <td>...</td>\n",
       "      <td>True Single</td>\n",
       "      <td>True Single</td>\n",
       "      <td>111436_WSDA_SF_2017</td>\n",
       "      <td>canola</td>\n",
       "      <td>center pivot</td>\n",
       "      <td>wsda</td>\n",
       "      <td>61</td>\n",
       "      <td>60.867042</td>\n",
       "      <td>2017/07/18</td>\n",
       "      <td>Grant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>single_38745_WSDA_SF_2018.jpg</td>\n",
       "      <td>single</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>single</td>\n",
       "      <td>single</td>\n",
       "      <td>single</td>\n",
       "      <td>single</td>\n",
       "      <td>single</td>\n",
       "      <td>True Single</td>\n",
       "      <td>True Single</td>\n",
       "      <td>...</td>\n",
       "      <td>True Single</td>\n",
       "      <td>True Single</td>\n",
       "      <td>38745_WSDA_SF_2018</td>\n",
       "      <td>grass hay</td>\n",
       "      <td>center pivot</td>\n",
       "      <td>wsda</td>\n",
       "      <td>79</td>\n",
       "      <td>78.935430</td>\n",
       "      <td>2018/10/17 00:00:00</td>\n",
       "      <td>Yakima</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         filename human_predict  prob_single prob_point3  \\\n",
       "0  single_111436_WSDA_SF_2017.jpg        single     1.000000      single   \n",
       "1   single_38745_WSDA_SF_2018.jpg        single     0.999998      single   \n",
       "\n",
       "  prob_point4 prob_point5 prob_point6 prob_point7 predType_point3  \\\n",
       "0      single      single      single      single     True Single   \n",
       "1      single      single      single      single     True Single   \n",
       "\n",
       "  predType_point4  ... predType_point6 predType_point7                   ID  \\\n",
       "0     True Single  ...     True Single     True Single  111436_WSDA_SF_2017   \n",
       "1     True Single  ...     True Single     True Single   38745_WSDA_SF_2018   \n",
       "\n",
       "     CropTyp       Irrigtn DataSrc Acres    ExctAcr              LstSrvD  \\\n",
       "0     canola  center pivot    wsda    61  60.867042           2017/07/18   \n",
       "1  grass hay  center pivot    wsda    79  78.935430  2018/10/17 00:00:00   \n",
       "\n",
       "   county  \n",
       "0   Grant  \n",
       "1  Yakima  \n",
       "\n",
       "[2 rows x 21 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expert_test_df = pd.merge(expert_test_df, meta, on=['ID'], how='left')\n",
    "expert_test_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "caa719d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "acr_predTypes = pd.DataFrame(columns=['pred_type'])\n",
    "lst = ['False Single', 'False Double', 'True Double', 'True Single']\n",
    "acr_predTypes[\"pred_type\"] = lst\n",
    "\n",
    "for ii in [3, 4, 5, 6, 7]:\n",
    "    curr_col = \"predType_point\" + str(ii)\n",
    "    A = expert_test_df[[curr_col, 'Acres']].groupby([curr_col]).sum()\n",
    "    A.rename(columns={\"Acres\": \"Acres_point\"+ str(ii)}, inplace=True)\n",
    "    acr_predTypes = pd.merge(acr_predTypes, A.reset_index(), \n",
    "                             left_on='pred_type', right_on=curr_col,\n",
    "                             how='left')\n",
    "for ii in [3, 4, 5, 6, 7]:\n",
    "    curr_col = \"predType_point\" + str(ii)\n",
    "    acr_predTypes.drop(curr_col, axis=\"columns\", inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ebc598c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = \"/Users/hn/Documents/01_research_data/NASA/ML_data/01_transfer_learning_result/\"\n",
    "out_name = out_dir + \"01_regular_TL_expert_\" + VI_idx + \"_Acreage_TFPR.csv\"\n",
    "acr_predTypes.to_csv(out_name, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6d5f5d0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Acres_point3</th>\n",
       "      <th>Acres_point4</th>\n",
       "      <th>Acres_point5</th>\n",
       "      <th>Acres_point6</th>\n",
       "      <th>Acres_point7</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pred_type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>True Single</th>\n",
       "      <td>12415</td>\n",
       "      <td>12415</td>\n",
       "      <td>12415</td>\n",
       "      <td>12335</td>\n",
       "      <td>12199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True Double</th>\n",
       "      <td>3596</td>\n",
       "      <td>3744</td>\n",
       "      <td>3744</td>\n",
       "      <td>3759</td>\n",
       "      <td>3759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>False Double</th>\n",
       "      <td>235</td>\n",
       "      <td>235</td>\n",
       "      <td>235</td>\n",
       "      <td>315</td>\n",
       "      <td>451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>False Single</th>\n",
       "      <td>454</td>\n",
       "      <td>306</td>\n",
       "      <td>306</td>\n",
       "      <td>291</td>\n",
       "      <td>291</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Acres_point3  Acres_point4  Acres_point5  Acres_point6  \\\n",
       "pred_type                                                              \n",
       "True Single          12415         12415         12415         12335   \n",
       "True Double           3596          3744          3744          3759   \n",
       "False Double           235           235           235           315   \n",
       "False Single           454           306           306           291   \n",
       "\n",
       "              Acres_point7  \n",
       "pred_type                   \n",
       "True Single          12199  \n",
       "True Double           3759  \n",
       "False Double           451  \n",
       "False Single           291  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorter=index_rows\n",
    "acr_predTypes = acr_predTypes.set_index('pred_type')\n",
    "acr_predTypes.loc[sorter]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "45c3446f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Acres_point3     219\n",
       "Acres_point4      71\n",
       "Acres_point5      71\n",
       "Acres_point6     -24\n",
       "Acres_point7    -160\n",
       "dtype: object"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(acr_predTypes.iloc[0, 1:]-acr_predTypes.iloc[1, 1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e2474529",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16700"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acr_predTypes['Acres_point3'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8235f590",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9f4b5684",
   "metadata": {},
   "source": [
    "# Non Expert Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c1009d",
   "metadata": {},
   "outputs": [],
   "source": [
    "nonExpert_test_dir = \"/Users/hn/Documents/01_research_data/NASA/ML_data/\" + \\\n",
    "                     \"limitCrops_nonExpert_images_\" + VI_idx + \"/\"\n",
    "\n",
    "test_filenames = os.listdir(test_dir)\n",
    "test_df = pd.DataFrame({'filename': test_filenames})\n",
    "nb_samples = test_df.shape[0]\n",
    "\n",
    "test_df[\"human_predict\"] = test_df.filename.str.split(\"_\", expand=True)[0]\n",
    "test_df[\"prob_single\"]=-1.0\n",
    "print (test_df.shape)\n",
    "test_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab257a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ae73a6bc",
   "metadata": {},
   "source": [
    "# filter out experts label from non-expert set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58bf0754",
   "metadata": {},
   "outputs": [],
   "source": [
    "fileNameList = list(test_df.filename)\n",
    "IDs_inpath = [ \"_\".join(x.split(\"_\")[1:])[:-4] for x in fileNameList]\n",
    "test_df[\"ID\"] = IDs_inpath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "681f6a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_datagen = ImageDataGenerator(featurewise_center=True)\n",
    "# Image_Size = (224, 224)\n",
    "# test_generator = test_datagen.flow_from_directory(test_dir,\n",
    "#                                                   target_size=Image_Size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b428e6bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f412a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027cd865",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have done this once before. So, commented out here. and read below.\n",
    "for idx in test_df.index:\n",
    "    img = load_image(test_dir + test_df.loc[idx, 'filename'])\n",
    "    test_df.loc[idx, 'prob_single'] = model.predict(img)[0][0]\n",
    "    \n",
    "\n",
    "for prob in [0.3, 0.4, 0.5, 0.6, 0.7]:\n",
    "    colName = \"prob_point\"+str(prob)[2:]\n",
    "    test_df.loc[test_df.prob_single<prob, colName] = 'double'\n",
    "    test_df.loc[test_df.prob_single>=prob, colName] = 'single'\n",
    "\n",
    "out_dir = \"/Users/hn/Documents/01_research_data/NASA/ML_data/01_transfer_learning_result/\"\n",
    "out_name = out_dir + \"01_regular_nonExpertLimitCrops_TL_predictions_\" + VI_idx + \".csv\"\n",
    "test_df.to_csv(out_name, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d0fe89",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.loc[40:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0eb3a79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b775ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = \"/Users/hn/Documents/01_research_data/NASA/ML_data/01_transfer_learning_result/\"\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "test_df = pd.read_csv(out_dir + \"01_regular_nonExpertLimitCrops_TL_predictions_\" + VI_idx + \".csv\")\n",
    "test_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d71e505",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.loc[30:40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d81c49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip show keras\n",
    "# pip list --outdated\n",
    "# !pip3 install --upgrade keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "157d8259",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ii in [3, 4, 5, 6, 7]:\n",
    "    curr_prob = \"prob_point\"+str(ii)\n",
    "    curr_pred_type = \"predType_point\" + str(ii)\n",
    "    test_df[curr_pred_type]=\"a\"\n",
    "    for idx in test_df.index:\n",
    "        if test_df.loc[idx, \"human_predict\"]==test_df.loc[idx, curr_prob]==\"single\":\n",
    "            test_df.loc[idx, curr_pred_type]=\"True Single\"\n",
    "        elif test_df.loc[idx, \"human_predict\"]==test_df.loc[idx, curr_prob]==\"double\":\n",
    "            test_df.loc[idx, curr_pred_type]=\"True Double\"\n",
    "        elif test_df.loc[idx, \"human_predict\"]==\"double\" and test_df.loc[idx, curr_prob]==\"single\":\n",
    "            test_df.loc[idx, curr_pred_type]=\"False Single\"\n",
    "        elif test_df.loc[idx, \"human_predict\"]==\"single\" and test_df.loc[idx, curr_prob]==\"double\":\n",
    "            test_df.loc[idx, curr_pred_type]=\"False Double\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8bada95",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18438ed1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0735b262",
   "metadata": {},
   "outputs": [],
   "source": [
    "needed_cols = [\"predType_point3\", \"predType_point4\", \n",
    "               \"predType_point5\", \n",
    "               \"predType_point6\", \"predType_point7\"]\n",
    "test_df_trimmed = test_df[needed_cols].copy()\n",
    "test_df_trimmed.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be23be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "TFR=pd.DataFrame()\n",
    "for col in test_df_trimmed.columns:\n",
    "    TFR[col]=test_df_trimmed[col].value_counts()\n",
    "TFR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c08db0d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_name = out_dir + \"01_TL_predType_TFR.csv\"\n",
    "# TFR.to_csv(out_name, index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de8d1817",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "563976d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df[\"ID\"] = test_df.filename.str.split(\"_\", expand=True)[1]+ \"_\" + \\\n",
    "                test_df.filename.str.split(\"_\", expand=True)[2]+ \"_\" + \\\n",
    "                test_df.filename.str.split(\"_\", expand=True)[3]+ \"_\" + \\\n",
    "                test_df.filename.str.split(\"_\", expand=True)[4].str.split(\".\", expand=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad87f687",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae7518cf",
   "metadata": {},
   "source": [
    "# Read field info to add areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cdcd498",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_set = pd.read_csv(\"/Users/hn/Documents/01_research_data/NASA/parameters/evaluation_set.csv\")\n",
    "eval_set.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57da8654",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.merge(test_df, eval_set, on=['ID'], how='left')\n",
    "test_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d0e003c",
   "metadata": {},
   "outputs": [],
   "source": [
    "acr_predTypes = pd.DataFrame(columns=['pred_type'])\n",
    "lst = ['False Single', 'False Double', 'True Double', 'True Single']\n",
    "acr_predTypes[\"pred_type\"] = lst\n",
    "\n",
    "for ii in [3, 4, 5, 6, 7]:\n",
    "    curr_col = \"predType_point\" + str(ii)\n",
    "    A = test_df[[curr_col, 'Acres']].groupby([curr_col]).sum()\n",
    "    A.rename(columns={\"Acres\": \"Acres_point\"+ str(ii)}, inplace=True)\n",
    "    acr_predTypes = pd.merge(acr_predTypes, A.reset_index(), \n",
    "                             left_on='pred_type', right_on=curr_col,\n",
    "                             how='left')\n",
    "for ii in [3, 4, 5, 6, 7]:\n",
    "    curr_col = \"predType_point\" + str(ii)\n",
    "    acr_predTypes.drop(curr_col, axis=\"columns\", inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d482b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "acr_predTypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e77230a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = \"/Users/hn/Documents/01_research_data/NASA/ML_data/01_transfer_learning_result/\"\n",
    "out_name = out_dir + \"01_regular_nonExpertLimitCrops_TL_\" + VI_idx + \"_Acreage_TFPR.csv\"\n",
    "acr_predTypes.to_csv(out_name, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e11cefe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de51cd11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcac9230",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b483f198",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa28a9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e37574",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12735820",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
