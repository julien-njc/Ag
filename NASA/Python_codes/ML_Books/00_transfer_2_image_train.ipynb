{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "272d28c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from random import seed\n",
    "from random import random\n",
    "\n",
    "\n",
    "from datetime import date\n",
    "import time\n",
    "import scipy, scipy.signal\n",
    "import os, os.path\n",
    "import shutil\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pylab import imshow\n",
    "\n",
    "# vgg16 model used for transfer learning on the dogs and cats dataset\n",
    "from matplotlib import pyplot\n",
    "# from keras.utils import to_categorical\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "# from keras.optimizers import SGD\n",
    "\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "\n",
    "# from keras.optimizers import gradient_descent_v2\n",
    "# SGD = gradient_descent_v2.SGD(...)\n",
    "\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import sys\n",
    "sys.path.append('/Users/hn/Documents/00_GitHub/Ag/NASA/Python_codes/')\n",
    "import NASA_core as nc\n",
    "# import NASA_plot_core.py as rcp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c06e224e",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx=\"EVI\"\n",
    "data_dir = \"/Users/hn/Documents/01_research_data/NASA/VI_TS/05_SG_TS/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4148a26d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>human_system_start_time</th>\n",
       "      <th>EVI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>135073_WSDA_SF_2015</td>\n",
       "      <td>2015-01-10</td>\n",
       "      <td>0.054429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>135073_WSDA_SF_2015</td>\n",
       "      <td>2015-01-20</td>\n",
       "      <td>0.051731</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    ID human_system_start_time       EVI\n",
       "0  135073_WSDA_SF_2015              2015-01-10  0.054429\n",
       "1  135073_WSDA_SF_2015              2015-01-20  0.051731"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_names = [\"SG_Walla2015_EVI_JFD.csv\", \"SG_AdamBenton2016_EVI_JFD.csv\", \n",
    "              \"SG_Grant2017_EVI_JFD.csv\", \"SG_FranklinYakima2018_EVI_JFD.csv\"]\n",
    "\n",
    "data=pd.DataFrame()\n",
    "\n",
    "for file in file_names:\n",
    "    curr_file=pd.read_csv(data_dir + file)\n",
    "    curr_file['human_system_start_time'] = pd.to_datetime(curr_file['human_system_start_time'])\n",
    "    \n",
    "    # These data are for 3 years. The middle one is the correct one\n",
    "    all_years = sorted(curr_file.human_system_start_time.dt.year.unique())\n",
    "    if len(all_years)==3 or len(all_years)==2:\n",
    "        proper_year = all_years[1]\n",
    "    elif len(all_years)==1:\n",
    "        proper_year = all_years[0]\n",
    "\n",
    "    curr_file = curr_file[curr_file.human_system_start_time.dt.year==proper_year]\n",
    "    data=pd.concat([data, curr_file])\n",
    "\n",
    "data.reset_index(drop=True, inplace=True)\n",
    "data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e6ace2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "crr_fld=data[data.ID==data.ID.unique()[0]].copy()\n",
    "SFYr = crr_fld.human_system_start_time.dt.year.unique()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de9e5443",
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_granular_table = nc.create_calendar_table(SF_year = SFYr)\n",
    "fine_granular_table = pd.merge(fine_granular_table, crr_fld, on=['human_system_start_time'], how='left')\n",
    "\n",
    "fine_granular_table.ID = crr_fld.ID.unique()[0]\n",
    "# replace NAs with -1.5. Because, that is what the function fill_theGap_linearLine()\n",
    "# uses as indicator for missing values\n",
    "fine_granular_table.fillna(value={idx:-1.5}, inplace=True)\n",
    "fine_granular_table.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b76ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_granular_table = nc.fill_theGap_linearLine(a_regularized_TS=fine_granular_table, \n",
    "                                                V_idx=idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ab2e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots();\n",
    "fig.set_size_inches(10, 2.5)\n",
    "ax.grid(True);\n",
    "ax.scatter(fine_granular_table['human_system_start_time'], fine_granular_table[idx], \n",
    "           marker='o', s=5, c='r', label=idx)\n",
    "\n",
    "ax.set_xlabel('time'); # , labelpad = 15\n",
    "ax.set_ylabel(idx, fontsize=12); # , labelpad = 15\n",
    "ax.tick_params(axis = 'y', which = 'major');\n",
    "ax.legend(loc = \"upper left\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da41624",
   "metadata": {},
   "source": [
    "# Discretize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a67c8d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "epsilon = 2*math.ulp(1.0)\n",
    "\n",
    "fine_granular_table[fine_granular_table[idx]<0][idx]=0 # Set negatives to zero\n",
    "fine_granular_table[fine_granular_table[idx]==1][idx]= 1-epsilon # Avoid having 1 to avoid problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ddd1ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_bin_size = 0.01\n",
    "number_of_rows = int(1/y_bin_size)\n",
    "n_bins = number_of_rows\n",
    "\n",
    "n_bins = number_of_rows\n",
    "\n",
    "\"\"\"\n",
    "  The following two lines works for EVI/NDVI, but not generally.\n",
    "  It works when we are binning [0, 1]\n",
    "     v = np.array([1, 2, 3, 4, 5])\n",
    "     n_bins = 5\n",
    "     ones_indices = np.floor(v * n_bins)\n",
    "     ones_indices = list((ones_indices).astype(int))\n",
    "     M = np.zeros((len(v), n_bins))\n",
    "     M[np.arange(len(v)), ones_indices] = 1\n",
    "\"\"\"\n",
    "# ones_indices = np.floor(fine_granular_table[idx] * n_bins)\n",
    "# ones_indices = list((ones_indices).astype(int))\n",
    "\n",
    "ones_indices = list(pd.cut(x=fine_granular_table[idx], bins=np.arange(0, 1, y_bin_size), labels=False))\n",
    "\n",
    "image_matrix = np.zeros((n_bins, len(fine_granular_table[idx])))\n",
    "image_matrix[ones_indices, np.arange(len(fine_granular_table[idx]))] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e044a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# M[np.arange(len(v)), ones_indices] = 1\n",
    "# n_bins = number_of_rows\n",
    "# v = fine_granular_table[idx]\n",
    "# ones_indices = np.floor(v * n_bins)\n",
    "# ones_indices = list((ones_indices).astype(int))\n",
    "\n",
    "# M = np.zeros((len(v), n_bins))\n",
    "# M[np.arange(len(v)), ones_indices] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1393a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# v = np.array([.1, .2, .3, .4, .5, .9])\n",
    "# n_bins = 5\n",
    "# ones_indices = np.floor(v * n_bins)\n",
    "# ones_indices = list((ones_indices).astype(int))\n",
    "# M = np.zeros((len(v), n_bins))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477e69c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pylab import imshow\n",
    "fig, ax = plt.subplots();\n",
    "fig.set_size_inches(10, 2.5)\n",
    "imshow(image_matrix, origin='lower')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4abf3d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_matrix3D = np.tile(image_matrix,(3, 1, 1))\n",
    "image_matrix3D = np.repeat(image_matrix[:, :, np.newaxis], 3, axis=2)\n",
    "image_matrix3D.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9add7997",
   "metadata": {},
   "source": [
    "### Plot 3D verson of the image_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db9c7a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 1, figsize=(10, 6),\n",
    "                        gridspec_kw={'hspace': 0.2, 'wspace': .1});\n",
    "\n",
    "(ax1, ax2) = axs;\n",
    "ax1.grid(True); ax2.grid(True)\n",
    "\n",
    "ax1.scatter(fine_granular_table['human_system_start_time'], fine_granular_table[idx], \n",
    "            marker='o', s=5, c='r', label=idx);\n",
    "left = fine_granular_table['human_system_start_time'][0]\n",
    "right = fine_granular_table['human_system_start_time'].values[-1]\n",
    "ax1.set_xlim([left, right]) # the following line alsow orks\n",
    "\n",
    "\n",
    "ax2.imshow(image_matrix3D, origin='lower');\n",
    "\n",
    "# plt.tight_layout()\n",
    "# Make space for title\n",
    "plt.subplots_adjust(top=0.85)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03d597b4",
   "metadata": {},
   "source": [
    "# Read Training Set Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f3265a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set_dir = \"/Users/hn/Documents/01_research_data/NASA/training_set_data/\"\n",
    "train_labels = pd.read_csv(training_set_dir+\"train_labels.csv\")\n",
    "train_labels.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee8c7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # define cnn model\n",
    "# def define_model():\n",
    "#     # load model\n",
    "#     model = VGG16(include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "#     # mark loaded layers as not trainable\n",
    "#     for layer in model.layers:\n",
    "#         layer.trainable = False\n",
    "    \n",
    "#     # add new classifier layers\n",
    "#     flat1 = Flatten()(model.layers[-1].output)\n",
    "#     class1 = Dense(128, activation='relu', kernel_initializer='he_uniform')(flat1)\n",
    "#     output = Dense(1, activation='sigmoid')(class1)\n",
    "    \n",
    "#     # define new model\n",
    "#     model = Model(inputs=model.inputs, outputs=output)\n",
    "    \n",
    "#     # compile model\n",
    "#     opt = SGD(learning_rate=0.001, momentum=0.9)\n",
    "#     model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b73225",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot dog photos from the dogs vs cats dataset\n",
    "from matplotlib import pyplot\n",
    "from matplotlib.image import imread\n",
    "# define location of dataset\n",
    "train_folder = '/Users/hn/Documents/01_research_data/dogs-vs-cats/train/'\n",
    "test_folder = \"/Users/hn/Documents/01_research_data/dogs-vs-cats/test1/\"\n",
    "# plot first few images\n",
    "for i in range(9):\n",
    "    # define subplot\n",
    "    pyplot.subplot(330 + 1 + i)\n",
    "    # define filename\n",
    "    filename = train_folder + 'dog.' + str(i) + '.jpg'\n",
    "    # load image pixels\n",
    "    image = imread(filename)\n",
    "    # plot raw pixel data\n",
    "    pyplot.imshow(image)\n",
    "# show the figure\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "317de5eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import load_img\n",
    "photo = load_img(train_folder + 'dog.' + str(0) + '.jpg', target_size=(200, 200))\n",
    "print (photo.size)\n",
    "photo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d1ff01b",
   "metadata": {},
   "source": [
    "# Pre-Process Photo Sizes (Optional)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e84fba17",
   "metadata": {},
   "source": [
    "# Pre-Process Photo Sizes (Optional)\n",
    "# load dogs vs cats dataset, reshape and save to a new file\n",
    "from numpy import asarray\n",
    "from numpy import save\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "# define location of dataset\n",
    "folder = train_folder\n",
    "photos, labels = list(), list()\n",
    "# enumerate files in the directory\n",
    "for file in os.listdir(folder):\n",
    "    # determine class\n",
    "    output = 0.0\n",
    "    if file.startswith('dog'):\n",
    "        output = 1.0\n",
    "    # load image\n",
    "    photo = load_img(folder + file, target_size=(200, 200))\n",
    "    # convert to numpy array\n",
    "    photo = img_to_array(photo)\n",
    "    # store\n",
    "    photos.append(photo)\n",
    "    labels.append(output)\n",
    "# convert to a numpy arrays\n",
    "photos = asarray(photos)\n",
    "labels = asarray(labels)\n",
    "print(photos.shape, labels.shape)\n",
    "# save the reshaped photos\n",
    "save(folder + 'dogs_vs_cats_photos.npy', photos)\n",
    "save(folder + 'dogs_vs_cats_labels.npy', labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b480d09b",
   "metadata": {},
   "source": [
    "# Load prepared data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1dc736e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load and confirm the shape\n",
    "# from numpy import load\n",
    "# photos = load(train_folder +'dogs_vs_cats_photos.npy')\n",
    "# labels = load(train_folder +'dogs_vs_cats_labels.npy')\n",
    "# print(photos.shape, labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87a5cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (train_folder)\n",
    "len(os.listdir(train_folder))\n",
    "# os.chdir('/tmp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db9d4b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create directories\n",
    "dataset_home = train_folder + 'dataset_dogs_vs_cats/'\n",
    "subdirs = ['train/', 'test/']\n",
    "\n",
    "for subdir in subdirs:\n",
    "    # create label subdirectories\n",
    "    labeldirs = ['dogs/', 'cats/']\n",
    "    for labldir in labeldirs:\n",
    "        newdir = dataset_home + subdir + labldir\n",
    "        os.makedirs(newdir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7681d355",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# We have done this once before! So, I comment out this cell.\n",
    "#\n",
    "# seed random number generator\n",
    "seed(1)\n",
    "# define ratio of pictures to use for validation\n",
    "val_ratio = 0.25\n",
    "\n",
    "# copy training dataset images into subdirectories\n",
    "\n",
    "src_directory = train_folder\n",
    "for file in os.listdir(src_directory)[:2000]:\n",
    "    src = src_directory + '/' + file\n",
    "    dst_dir = 'train/'\n",
    "    if random() < val_ratio:\n",
    "        dst_dir = 'test/'\n",
    "    if file.startswith('cat'):\n",
    "        dst = dataset_home + dst_dir + 'cats/'  + file\n",
    "        shutil.copyfile(src, dst)\n",
    "    elif file.startswith('dog'):\n",
    "        dst = dataset_home + dst_dir + 'dogs/'  + file\n",
    "        shutil.copyfile(src, dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a86303-bcd4-4928-8b70-615d4dc227eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "893fc6b0",
   "metadata": {},
   "source": [
    "### Develop a Baseline CNN Model\n",
    "\n",
    "# Skip some steps here and jump to transfer learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be3e50a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_folder=\"/Users/hn/Documents/01_research_data/dogs-vs-cats/train/dataset_dogs_vs_cats/train/\"\n",
    "test_folder=\"/Users/hn/Documents/01_research_data/dogs-vs-cats/train/dataset_dogs_vs_cats/test/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ffa34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c52b77ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define CNN model\n",
    "def define_model():\n",
    "    # load model\n",
    "    model = VGG16(include_top=False, input_shape=(224, 224, 3))\n",
    "    # mark loaded layers as not trainable\n",
    "    for layer in model.layers:\n",
    "        layer.trainable = False\n",
    "    # add new classifier layers\n",
    "    flat1 = Flatten()(model.layers[-1].output)\n",
    "    class1 = Dense(128, activation='relu', kernel_initializer='he_uniform')(flat1)\n",
    "    output = Dense(1, activation='sigmoid')(class1)\n",
    "    # define new model\n",
    "    model = Model(inputs=model.inputs, outputs=output)\n",
    "    # compile model\n",
    "    opt = SGD(learning_rate=0.001, momentum=0.9)\n",
    "    model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# plot diagnostic learning curves\n",
    "def summarize_diagnostics(_history):\n",
    "    # plot loss\n",
    "    pyplot.subplot(211)\n",
    "    pyplot.title('Cross Entropy Loss')\n",
    "    pyplot.plot(_history.history['loss'], color='blue', label='train')\n",
    "    pyplot.plot(_history.history['val_loss'], color='orange', label='test')\n",
    "    pyplot.legend(loc = \"upper right\");\n",
    "    # plot accuracy\n",
    "    pyplot.subplot(212)\n",
    "    pyplot.title('Classification Accuracy')\n",
    "    pyplot.plot(_history.history['accuracy'], color='blue', label='train')\n",
    "    pyplot.plot(_history.history['val_accuracy'], color='orange', label='test')\n",
    "    \n",
    "    pyplot.subplots_adjust(left=0.1,\n",
    "                           bottom=0.1, \n",
    "                           right=0.9, \n",
    "                           top=0.9, \n",
    "                           wspace=0.4, \n",
    "                           hspace=0.4)\n",
    "    pyplot.legend(loc = \"upper left\");\n",
    "    \n",
    "    # save plot to file\n",
    "    plot_dir = \"/Users/hn/Documents/01_research_data/dogs-vs-cats/\"\n",
    "    filename = plot_dir + \"my_plot_one.png\"\n",
    "    pyplot.savefig(filename, dpi=400, bbox_inches='tight')\n",
    "    pyplot.close()\n",
    "    \n",
    "# run the test harness for evaluating a model\n",
    "def run_test_harness():\n",
    "    # define model\n",
    "    model = define_model()\n",
    "    # create data generator\n",
    "    datagen = ImageDataGenerator(featurewise_center=True)\n",
    "    # specify imagenet mean values for centering\n",
    "    datagen.mean = [123.68, 116.779, 103.939]\n",
    "    # prepare iterator\n",
    "    train_it = datagen.flow_from_directory(train_folder, # 'dataset_dogs_vs_cats/train/',\n",
    "                                           class_mode='binary', batch_size=64, target_size=(224, 224))\n",
    "    test_it = datagen.flow_from_directory(test_folder, # 'dataset_dogs_vs_cats/test/',\n",
    "                                          class_mode='binary', batch_size=64, target_size=(224, 224))\n",
    "    # fit model\n",
    "    _history = model.fit(train_it, steps_per_epoch=len(train_it),\n",
    "                         validation_data=test_it, \n",
    "                         validation_steps=len(test_it), \n",
    "                         epochs=5, verbose=1) # epochs=10\n",
    "    # evaluate model\n",
    "    _, acc = model.evaluate(test_it, steps=len(test_it), verbose=0) # model.evaluate_generator\n",
    "    print('> %.3f' % (acc * 100.0))\n",
    "    # learning curves\n",
    "    summarize_diagnostics(_history)\n",
    "    return (_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7acdf52e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# entry point, run the test harness\n",
    "# %time\n",
    "start_time = time.time()\n",
    "a_model_with_history = run_test_harness()\n",
    "end_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d40b5a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "summarize_diagnostics(a_model_with_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31bed658",
   "metadata": {},
   "source": [
    "# Finalize the Model and Make Predictions\n",
    "\n",
    "**Prepare Final Dataset**\n",
    "\n",
    "A final model is typically fit on all available data, such as the combination of all train and test datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fbf872c",
   "metadata": {},
   "source": [
    "# Prepare final dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "548eb3d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# organize dataset into a useful structure\n",
    "# create directories\n",
    "dataset_home = '/Users/hn/Documents/01_research_data/dogs-vs-cats/train/'\n",
    "# create label subdirectories\n",
    "labeldirs = ['separate_dog_cat/dogs/', 'separate_dog_cat/cats/']\n",
    "for labldir in labeldirs:\n",
    "    newdir = dataset_home + labldir\n",
    "    os.makedirs(newdir, exist_ok=True)\n",
    "    \n",
    "# copy training dataset images into subdirectories\n",
    "src_directory = dataset_home\n",
    "for file in os.listdir(src_directory)[:2000]:  # I am doing this so that the training won't take too long\n",
    "    src = src_directory + '/' + file\n",
    "    if file.startswith('cat'):\n",
    "        dst = dataset_home + 'separate_dog_cat/cats/'  + file\n",
    "        shutil.copyfile(src, dst)\n",
    "    elif file.startswith('dog'):\n",
    "        dst = dataset_home + 'separate_dog_cat/dogs/'  + file\n",
    "        shutil.copyfile(src, dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a528b3b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define cnn model\n",
    "\n",
    "def define_model():\n",
    "    # load model\n",
    "    model = VGG16(include_top=False, input_shape=(224, 224, 3))\n",
    "    # mark loaded layers as not trainable\n",
    "    for layer in model.layers:\n",
    "        layer.trainable = False\n",
    "    # add new classifier layers\n",
    "    flat1 = Flatten()(model.layers[-1].output)\n",
    "    class1 = Dense(128, activation='relu', kernel_initializer='he_uniform')(flat1)\n",
    "    output = Dense(1, activation='sigmoid')(class1)\n",
    "    # define new model\n",
    "    model = Model(inputs=model.inputs, outputs=output)\n",
    "    # compile model\n",
    "    opt = SGD(learning_rate=0.001, momentum=0.9)\n",
    "    model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# run the test harness for evaluating a model\n",
    "def run_test_harness():\n",
    "    # define model\n",
    "    _model = define_model()\n",
    "    # create data generator\n",
    "    datagen = ImageDataGenerator(featurewise_center=True)\n",
    "    \n",
    "    # specify imagenet mean values for centering\n",
    "    datagen.mean = [123.68, 116.779, 103.939]\n",
    "    \n",
    "    # prepare iterator\n",
    "    train_separate_dir = \"/Users/hn/Documents/01_research_data/dogs-vs-cats/train/separate_dog_cat/\"\n",
    "    train_it = datagen.flow_from_directory(train_separate_dir,\n",
    "                                           class_mode='binary', \n",
    "                                           batch_size=64, \n",
    "                                           target_size=(224, 224))\n",
    "    # fit model\n",
    "    _model = _model.fit(train_it, \n",
    "                        steps_per_epoch=len(train_it), \n",
    "                        epochs=10, verbose=1)\n",
    "    # save model\n",
    "    model_dir = \"/Users/hn/Documents/01_research_data/dogs-vs-cats/\"\n",
    "    _model.save(model_dir+'final_model_cats_dogs.h5')\n",
    "    return(_model)\n",
    "\n",
    "# entry point, run the test harness\n",
    "start_time = time.time()\n",
    "trained_model = run_test_harness()\n",
    "end_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8e753a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b45b709",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc63532",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "694abe21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot loss\n",
    "pyplot.subplot(211)\n",
    "pyplot.title('Cross Entropy Loss')\n",
    "pyplot.plot(trained_model.history['loss'], color='blue', label='train')\n",
    "# pyplot.plot(trained_model.history['val_loss'], color='orange', label='test')\n",
    "pyplot.legend(loc = \"upper right\");\n",
    "\n",
    "# plot accuracy\n",
    "pyplot.subplot(212)\n",
    "pyplot.title('Classification Accuracy')\n",
    "pyplot.plot(trained_model.history['accuracy'], color='blue', label='train')\n",
    "# pyplot.plot(trained_model.history['val_accuracy'], color='orange', label='test')\n",
    "pyplot.legend(loc = \"upper left\");\n",
    "\n",
    "# save plot to file\n",
    "plot_dir = \"/Users/hn/Documents/01_research_data/dogs-vs-cats/\"\n",
    "filename = plot_dir + \"my_plot_one.png\"\n",
    "pyplot.savefig(filename, dpi=300)\n",
    "pyplot.close()\n",
    "\n",
    "\n",
    "summarize_diagnostics(trained_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a9ac3a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model.history['accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63568460",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
